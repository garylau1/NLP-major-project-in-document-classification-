{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b925966-16d9-4ecc-a0a9-747453e98cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUG: RAW MODEL OUTPUT ===\n",
      "\n",
      "{\"reasoningContent\": {\"reasoningText\": {\"text\": \"Okay, let's tackle this OCR text. First, I need to parse all the required fields. The name is Fox Gonzalez WEAVER, that's straightforward. The address is the line starting with 48, so that's \\\"48 FHQ WCMEAPQJ LHQABHJ DAGZJBC NSW 4819\\\". \\n\\nDate of Birth is 07 MAR 1983, which converts to 07/03/1983. Expiry Date is 17 DEC 2020, so 17/12/2020. There's no date of issue mentioned, so that's empty.\\n\\nLicence Number: The line says \\\"Licence Na 40419631\\\", which I think is a typo for \\\"Licence No\\\", so the number is 40419631. Passport number isn't present. Card Number is \\\"5 610 827 648\\\", which should be concatenated to 5610827648. Identity Number isn't here either.\\n\\nFor non_pii_text, each line needs processing. The first line is \\\"Learner Driver Licence New South Wales, Australia\\\" \\u2013 no numbers, so it stays. \\\"Fox Gonzalez WEAVER\\\" becomes just the name label, but since it's the name line, maybe it's part of non_pii? Wait, the example included the name line as part of non_pii. Wait, no, in the example, the name was in the ground truth, but the non_pii_text included the static lines. Wait, looking at the example, the name line was part of the pseudo text, but in the non_pii_text, they only included labels. Wait, the example's non_pii_text had \\\"Learner Driver Licence...\\\", \\\"Licence No\\\", \\\"Licence Class...\\\", \\\"Date of Birth\\\", \\\"Expiry Date\\\", \\\"Card Number\\\". The name line wasn't included because it's PII. So in this case, the line \\\"Fox Gonzalez WEAVER\\\" would be the name, which is PII, so the non_pii_text would process each line, removing numbers and keeping the label part. Let's go line by line.\\n\\nOriginal lines:\\n1. Learner Driver Licence New South Wales, Australia\\n2. Fox Gonzalez WEAVER\\n3. Card Number 5 610 827 648\\n4. 48 FHQ WCMEAPQJ LHQABHJ DAGZJBC NSW 4819\\n5. Licence Na 40419631\"}}}\n",
      "\n",
      "=== DEBUG: CLEANED TEXT ===\n",
      "\n",
      "{\"reasoningContent\": {\"reasoningText\": {\"text\": \"Okay, let's tackle this OCR text. First, I need to parse all the required fields. The name is Fox Gonzalez WEAVER, that's straightforward. The address is the line starting with 48, so that's \\\"48 FHQ WCMEAPQJ LHQABHJ DAGZJBC NSW 4819\\\". \\n\\nDate of Birth is 07 MAR 1983, which converts to 07/03/1983. Expiry Date is 17 DEC 2020, so 17/12/2020. There's no date of issue mentioned, so that's empty.\\n\\nLicence Number: The line says \\\"Licence Na 40419631\\\", which I think is a typo for \\\"Licence No\\\", so the number is 40419631. Passport number isn't present. Card Number is \\\"5 610 827 648\\\", which should be concatenated to 5610827648. Identity Number isn't here either.\\n\\nFor non_pii_text, each line needs processing. The first line is \\\"Learner Driver Licence New South Wales, Australia\\\" \\u2013 no numbers, so it stays. \\\"Fox Gonzalez WEAVER\\\" becomes just the name label, but since it's the name line, maybe it's part of non_pii? Wait, the example included the name line as part of non_pii. Wait, no, in the example, the name was in the ground truth, but the non_pii_text included the static lines. Wait, looking at the example, the name line was part of the pseudo text, but in the non_pii_text, they only included labels. Wait, the example's non_pii_text had \\\"Learner Driver Licence...\\\", \\\"Licence No\\\", \\\"Licence Class...\\\", \\\"Date of Birth\\\", \\\"Expiry Date\\\", \\\"Card Number\\\". The name line wasn't included because it's PII. So in this case, the line \\\"Fox Gonzalez WEAVER\\\" would be the name, which is PII, so the non_pii_text would process each line, removing numbers and keeping the label part. Let's go line by line.\\n\\nOriginal lines:\\n1. Learner Driver Licence New South Wales, Australia\\n2. Fox Gonzalez WEAVER\\n3. Card Number 5 610 827 648\\n4. 48 FHQ WCMEAPQJ LHQABHJ DAGZJBC NSW 4819\\n5. Licence Na 40419631\"}}}\n",
      "\n",
      "===============================\n",
      "\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "10 validation errors for RawDocumentInfo\nname\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\naddress\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ndateOfBirth\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ndateOfIssue\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ndateOfExpiry\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nlicenceNumber\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\npassportNumber\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ncardNumber\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nidentityNumber\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nnon_pii_text\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 182\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 182\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mparse_document_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mocr_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m latency \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# predicted sets\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 149\u001b[0m, in \u001b[0;36mparse_document_text\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: ignored trailing data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(trailing[:\u001b[38;5;241m100\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# 4) unwrap common wrappers...\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#    (same as before)\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# 5) validate & return...\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m doc_info \u001b[38;5;241m=\u001b[39m \u001b[43mRawDocumentInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc_info\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/main.py:1162\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;129m@typing_extensions\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_obj\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:  \u001b[38;5;66;03m# noqa: D102\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mPydanticDeprecatedSince20\n\u001b[1;32m   1161\u001b[0m     )\n\u001b[0;32m-> 1162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/main.py:596\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    595\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 10 validation errors for RawDocumentInfo\nname\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\naddress\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ndateOfBirth\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ndateOfIssue\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ndateOfExpiry\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nlicenceNumber\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\npassportNumber\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\ncardNumber\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nidentityNumber\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing\nnon_pii_text\n  Field required [type=missing, input_value={'reasoningContent': {'re... Licence Na 40419631'}}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from json import JSONDecoder, JSONDecodeError\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Configuration\n",
    "# ----------------------------\n",
    "DATA_PATH = 'filtered_keys_edit11 1.json'\n",
    "REGION    = 'us-east-1'\n",
    "MODEL_ARN = \"arn:aws:bedrock:us-east-1:597571589726:inference-profile/us.deepseek.r1-v1:0\"\n",
    "\n",
    "# Bedrock client & model\n",
    "runtime  = boto3.client(\"bedrock-runtime\", region_name=REGION)\n",
    "model_id = MODEL_ARN\n",
    "\n",
    "# The prompt to send to Bedrock\n",
    "prompt_text = \"\"\"\n",
    "You are a document-reading assistant. \n",
    "I will give you a block of OCR’d text from a single document. \n",
    "Parse it and respond with a single JSON object with exactly these keys at the top level (no nesting):  \n",
    "- name (full name as string)  \n",
    "- address (string)   \n",
    "- dateOfBirth (string in DD/MM/YYYY format; if not found, \"\")   \n",
    "- dateOfIssue (string in DD/MM/YYYY format; if not found, \"\") \n",
    "- dateOfExpiry (string in DD/MM/YYYY format; if not found, \"\")  \n",
    "- licenceNumber (string; if not found, \"\")  \n",
    "- passportNumber (string; if not found, \"\")  \n",
    "- cardNumber (string; if not found, \"\")   \n",
    "- identityNumber (string; if not found, \"\")   \n",
    "- non_pii_text (array of strings):        \n",
    "For each non-empty line in the OCR text:       \n",
    "• Remove any numeric substrings, dates, or identifiers after the first digit or slash.        \n",
    "• Trim whitespace.      \n",
    "• Keep only the label portion (static text before any digit or slash).        \n",
    "• Do not include empty strings in the array. If a field isn’t present in the text, set its value to an empty string. \n",
    "Return only valid JSON: a flat object with exactly those keys, no extra nesting or commentary. \n",
    "\n",
    "Here is one example:\n",
    "\"0d4068c9-c6db-435d-9ed6-c0317ecddf62-enhanced-1_pt.json\": {\n",
    "      \"pseudo\": \"Learner Driver Licence New South Wales, Australia\\nChung Jenkins LAMBERT\\n. Card Number 2 659 265 265\\n95 QMXOYCPEVJZ RD IXTZQVT NSW 2282\\nLicence No 57250351 Licence Class C LRN\\nDate of Birth 06 JAN 1987\\nExpiry Date 03 AUG 2027\",\n",
    "      \"ground_truth\": {\n",
    "        \"name\": \"Chung Jenkins LAMBERT\",\n",
    "        \"address\": \"95 QMXOYCPEVJZ RD IXTZQVT NSW 2282\",\n",
    "        \"dateOfBirth\": \"06/01/1987\",\n",
    "        \"dateOfIssue\": \"\",\n",
    "        \"dateOfExpiry\": \"03/08/2027\",\n",
    "        \"licenceNumber\": \"57250351\",\n",
    "        \"passportNumber\": \"\",\n",
    "        \"cardNumber\": \"2659265265\",\n",
    "        \"identityNumber\": \"\",\n",
    "        \"non_pii_text\": [\n",
    "          \"Learner Driver Licence New South Wales, Australia\",\n",
    "          \"Licence No\",\n",
    "          \"Licence Class C LRN\",\n",
    "          \"Date of Birth\",\n",
    "          \"Expiry Date\",\n",
    "          \"Card Number\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Pydantic model for validation\n",
    "# ----------------------------\n",
    "class RawDocumentInfo(BaseModel):\n",
    "    name: str\n",
    "    address: str\n",
    "    dateOfBirth: str\n",
    "    dateOfIssue: str\n",
    "    dateOfExpiry: str\n",
    "    licenceNumber: str\n",
    "    passportNumber: str\n",
    "    cardNumber: str\n",
    "    identityNumber: str\n",
    "    non_pii_text: list[str]\n",
    "\n",
    "    @classmethod\n",
    "    def __get_validators__(cls):\n",
    "        yield from super().__get_validators__()\n",
    "        yield cls._ensure_list\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_list(v):\n",
    "        return v or []\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Function to parse a single OCR text block\n",
    "# ----------------------------\n",
    "def parse_document_text(input_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends the OCR’d text to Bedrock, cleans/parses the JSON response robustly (using raw_decode),\n",
    "    unwraps common wrappers, validates via Pydantic, and returns a dict with the\n",
    "    10 PII keys + non_pii_text. Includes debug prints for raw/cleaned payloads.\n",
    "    \"\"\"\n",
    "    resp = runtime.converse(\n",
    "        modelId=model_id,\n",
    "        messages=[{\"role\": \"user\", \"content\": [{\"text\": prompt_text}, {\"text\": input_text}]}],\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.0}\n",
    "    )\n",
    "\n",
    "    # 1) extract the raw model payload\n",
    "    raw = \"\"\n",
    "    out = resp.get(\"output\", {}).get(\"message\", {}).get(\"content\", [])\n",
    "    if out:\n",
    "        first = out[0]\n",
    "        if isinstance(first, dict):\n",
    "            raw = first.get(\"text\") or first.get(\"content\") or json.dumps(first)\n",
    "        elif isinstance(first, str):\n",
    "            raw = first\n",
    "    if not raw:\n",
    "        raw = json.dumps(resp)\n",
    "\n",
    "    # 2) strip control tokens/fences\n",
    "    cleaned = re.sub(r\"<\\|.*?\\|>\", \"\", raw, flags=re.S)\n",
    "    cleaned = re.sub(r\"^```(?:json)?\\s*\", \"\", cleaned, flags=re.I)\n",
    "    cleaned = re.sub(r\"\\s*```$\", \"\", cleaned, flags=re.I)\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    # ===== DEBUG DUMP =====\n",
    "    print(\"\\n=== DEBUG: RAW MODEL OUTPUT ===\\n\")\n",
    "    print(raw)\n",
    "    print(\"\\n=== DEBUG: CLEANED TEXT ===\\n\")\n",
    "    print(cleaned)\n",
    "    print(\"\\n===============================\\n\")\n",
    "\n",
    "    # 3) first JSON decode (ignore trailing)\n",
    "    decoder = JSONDecoder()\n",
    "    try:\n",
    "        parsed_json, end_idx = decoder.raw_decode(cleaned)\n",
    "    except JSONDecodeError as e:\n",
    "        print(\"❗ JSONDecodeError on cleaned text:\")\n",
    "        print(cleaned)\n",
    "        raise\n",
    "\n",
    "    trailing = cleaned[end_idx:].strip()\n",
    "    if trailing:\n",
    "        print(f\"Warning: ignored trailing data: {repr(trailing[:100])}\")\n",
    "\n",
    "    # 4) unwrap common wrappers...\n",
    "    #    (same as before)\n",
    "\n",
    "    # 5) validate & return...\n",
    "    doc_info = RawDocumentInfo.parse_obj(parsed_json)\n",
    "    return doc_info.dict()\n",
    "# ----------------------------\n",
    "# 4. Metric helper\n",
    "# ----------------------------\n",
    "def compute_metrics(tp: int, fp: int, fn: int):\n",
    "    p = tp/(tp+fp) if tp+fp > 0 else 0.0\n",
    "    r = tp/(tp+fn) if tp+fn > 0 else 0.0\n",
    "    f = 2*p*r/(p+r) if p+r > 0 else 0.0\n",
    "    return p, r, f\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Main loop: run, compare & collect metrics\n",
    "# ----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "#i=0\n",
    "#k=0\n",
    "for doc_type, files in data.items():\n",
    "    #i=i+1\n",
    "    #if i==20:\n",
    "        #break\n",
    "    for file_id, record in files.items():\n",
    "        #k=k+1\n",
    "        #if k==20:\n",
    "            #break\n",
    "        ocr_text = record.get('pseudo', '').strip()\n",
    "        if not ocr_text:\n",
    "            continue\n",
    "\n",
    "        start = time.time()\n",
    "        predicted = parse_document_text(ocr_text)\n",
    "        latency = time.time() - start\n",
    "\n",
    "        # predicted sets\n",
    "        pii_fields = {\n",
    "            predicted[k].strip()\n",
    "            for k in ['name','address','dateOfBirth','dateOfIssue',\n",
    "                      'dateOfExpiry','licenceNumber','passportNumber',\n",
    "                      'cardNumber','identityNumber']\n",
    "            if predicted.get(k, \"\").strip()\n",
    "        }\n",
    "        non_pii_fields = set(predicted.get('non_pii_text', []))\n",
    "\n",
    "        # ground-truth sets\n",
    "        gt = record.get('ground_truth', {}) or {}\n",
    "        gt_pii = {\n",
    "            gt[k].strip()\n",
    "            for k in ['name','address','dateOfBirth','dateOfIssue',\n",
    "                      'dateOfExpiry','licenceNumber','passportNumber',\n",
    "                      'cardNumber','identityNumber']\n",
    "            if gt.get(k, \"\").strip()\n",
    "        }\n",
    "        gt_non_pii = { s.strip() for s in gt.get('non_pii_text', []) if s.strip() }\n",
    "\n",
    "        # compute metrics\n",
    "        tp_pii = len(pii_fields & gt_pii)\n",
    "        fp_pii = len(pii_fields - gt_pii)\n",
    "        fn_pii = len(gt_pii - pii_fields)\n",
    "        p_pii, r_pii, f1_pii = compute_metrics(tp_pii, fp_pii, fn_pii)\n",
    "\n",
    "        tp_non = len(non_pii_fields & gt_non_pii)\n",
    "        fp_non = len(non_pii_fields - gt_non_pii)\n",
    "        fn_non = len(gt_non_pii - non_pii_fields)\n",
    "        p_non, r_non, f1_non = compute_metrics(tp_non, fp_non, fn_non)\n",
    "\n",
    "        total_gt = len(gt_pii) + len(gt_non_pii)\n",
    "        accuracy = (tp_pii + tp_non) / total_gt if total_gt > 0 else 0.0\n",
    "\n",
    "        # collect metrics\n",
    "        metrics_list.append({\n",
    "            'file_id': file_id,\n",
    "            'latency_s': round(latency, 2),\n",
    "            'p_pii': round(p_pii, 4),\n",
    "            'r_pii': round(r_pii, 4),\n",
    "            'f1_pii': round(f1_pii, 4),\n",
    "            'p_non': round(p_non, 4),\n",
    "            'r_non': round(r_non, 4),\n",
    "            'f1_non': round(f1_non, 4),\n",
    "            'accuracy': round(accuracy, 4),\n",
    "        })\n",
    "\n",
    "        # print per-doc\n",
    "        print(f\"File ID: {file_id}\")\n",
    "        print(f\"Latency: {latency:.2f}s\")\n",
    "        print(json.dumps(predicted, indent=2))\n",
    "        print(json.dumps(gt, indent=2))\n",
    "        print(\"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e706b6d-89b9-4759-b850-cabdbf2a9533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
